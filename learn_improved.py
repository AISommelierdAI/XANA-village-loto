#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹è‰¯ç‰ˆå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  - çš„ä¸­ç‡æ”¹å–„
ã‚ˆã‚Šè©³ç´°ãªåˆ†æã¨é‡ã¿èª¿æ•´
"""

import json
import statistics
from collections import defaultdict

class ImprovedLearningSystem:
    def __init__(self):
        self.weights = self.load_weights()
        self.evaluation_data = self.load_evaluation_data()
        
    def load_weights(self):
        """é‡ã¿è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open('weights.json', 'r', encoding='utf-8') as file:
                return json.load(file)
        except FileNotFoundError:
            return {
                "total_appearances": 0.15,
                "recent_appearances": 0.20,
                "missing_intervals": 0.20,
                "hot_cold": 0.10,
                "periodicity": 0.10,
                "regression_trend": 0.08,
                "moving_average": 0.08,
                "attraction_effect": 0.05,
                "distribution": 0.02,
                "adjacent_correlation": 0.02
            }
    
    def load_evaluation_data(self):
        """è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        data = {}
        
        # evaluation_results.jsonã‹ã‚‰èª­ã¿è¾¼ã¿
        try:
            with open('evaluation_results.json', 'r', encoding='utf-8') as file:
                data.update(json.load(file))
        except FileNotFoundError:
            pass
        
        # å€‹åˆ¥ã®è©•ä¾¡ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
        import glob
        for filename in glob.glob('evaluation_*.json'):
            try:
                with open(filename, 'r', encoding='utf-8') as file:
                    eval_data = json.load(file)
                    if 'date' in eval_data:
                        data[eval_data['date']] = eval_data
            except:
                continue
        
        return data
    
    def analyze_pattern_performance(self):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥æ€§èƒ½åˆ†æ"""
        pattern_stats = defaultdict(lambda: {
            'total_predictions': 0,
            'total_hits': 0,
            'hit_rates': [],
            'confidence_scores': []
        })
        
        for date, result in self.evaluation_data.items():
            if 'predictions' in result:
                for pred in result['predictions']:
                    pattern_num = pred.get('pattern', 1)
                    hits = pred.get('hits', pred.get('hit_count', 0))
                    confidence = pred.get('confidence', 50)
                    
                    stats = pattern_stats[pattern_num]
                    stats['total_predictions'] += 1
                    stats['total_hits'] += hits
                    stats['hit_rates'].append(hits / 6.0)  # 6å€‹ä¸­ä½•å€‹å½“ãŸã£ãŸã‹
                    stats['confidence_scores'].append(confidence)
        
        # çµ±è¨ˆè¨ˆç®—
        for pattern_num, stats in pattern_stats.items():
            if stats['total_predictions'] > 0:
                stats['average_hit_rate'] = statistics.mean(stats['hit_rates'])
                stats['average_confidence'] = statistics.mean(stats['confidence_scores'])
                stats['overall_hit_rate'] = stats['total_hits'] / (stats['total_predictions'] * 6)
                stats['confidence_accuracy'] = self.calculate_confidence_accuracy(
                    stats['confidence_scores'], stats['hit_rates']
                )
        
        return pattern_stats
    
    def calculate_confidence_accuracy(self, confidences, hit_rates):
        """ä¿¡é ¼åº¦ã¨çš„ä¸­ç‡ã®ç›¸é–¢ã‚’è¨ˆç®—"""
        if len(confidences) < 2:
            return 0.0
        
        # ä¿¡é ¼åº¦ã¨çš„ä¸­ç‡ã®ç›¸é–¢ä¿‚æ•°
        try:
            correlation = statistics.correlation(confidences, hit_rates)
            return max(0, correlation)  # è² ã®ç›¸é–¢ã¯0ã¨ã—ã¦æ‰±ã†
        except:
            return 0.0
    
    def analyze_feature_effectiveness(self):
        """ç‰¹å¾´é‡ã®æœ‰åŠ¹æ€§åˆ†æ"""
        feature_stats = defaultdict(lambda: {
            'high_confidence_hits': 0,
            'high_confidence_total': 0,
            'low_confidence_hits': 0,
            'low_confidence_total': 0
        })
        
        for date, result in self.evaluation_data.items():
            if 'predictions' in result:
                for pred in result['predictions']:
                    confidence = pred.get('confidence', 50)
                    hits = pred.get('hits', pred.get('hit_count', 0))
                    
                    # é«˜ä¿¡é ¼åº¦(80%ä»¥ä¸Š)ã¨ä½ä¿¡é ¼åº¦(80%æœªæº€)ã«åˆ†é¡
                    if confidence >= 80:
                        feature_stats['high_confidence']['high_confidence_hits'] += hits
                        feature_stats['high_confidence']['high_confidence_total'] += 1
                    else:
                        feature_stats['low_confidence']['low_confidence_hits'] += hits
                        feature_stats['low_confidence']['low_confidence_total'] += 1
        
        return feature_stats
    
    def calculate_weight_adjustments(self):
        """é‡ã¿èª¿æ•´è¨ˆç®—"""
        pattern_stats = self.analyze_pattern_performance()
        feature_stats = self.analyze_feature_effectiveness()
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1-3ã®æ€§èƒ½ã‚’åˆ†æï¼ˆé€šå¸¸æœ€ã‚‚ä¿¡é ¼åº¦ãŒé«˜ã„ï¼‰
        top_patterns = [1, 2, 3]
        top_pattern_performance = []
        
        for pattern_num in top_patterns:
            if pattern_num in pattern_stats:
                stats = pattern_stats[pattern_num]
                if stats['total_predictions'] > 0:
                    top_pattern_performance.append(stats['average_hit_rate'])
        
        # å…¨ä½“ã®å¹³å‡çš„ä¸­ç‡
        overall_hit_rate = statistics.mean(top_pattern_performance) if top_pattern_performance else 0.5
        
        # é‡ã¿èª¿æ•´ã®æ–¹å‘æ€§ã‚’æ±ºå®š
        adjustments = {}
        
        if overall_hit_rate >= 0.25:  # 25%ä»¥ä¸Šã®çš„ä¸­ç‡
            # ç¾åœ¨ã®é‡ã¿ã‚’ç¶­æŒã¾ãŸã¯å¾®èª¿æ•´
            adjustments = {
                "total_appearances": 0.0,
                "recent_appearances": 0.0,
                "missing_intervals": 0.0,
                "hot_cold": 0.0,
                "periodicity": 0.0,
                "regression_trend": 0.0,
                "moving_average": 0.0,
                "attraction_effect": 0.0,
                "distribution": 0.0,
                "adjacent_correlation": 0.0
            }
        elif overall_hit_rate >= 0.15:  # 15-25%ã®çš„ä¸­ç‡
            # ä¸­ç¨‹åº¦ã®èª¿æ•´
            adjustments = {
                "total_appearances": -0.005,
                "recent_appearances": -0.005,
                "missing_intervals": +0.010,
                "hot_cold": +0.005,
                "periodicity": +0.005,
                "regression_trend": +0.005,
                "moving_average": +0.005,
                "attraction_effect": +0.005,
                "distribution": +0.005,
                "adjacent_correlation": +0.005
            }
        else:  # 15%æœªæº€ã®çš„ä¸­ç‡
            # å¤§å¹…ãªèª¿æ•´
            adjustments = {
                "total_appearances": -0.010,
                "recent_appearances": -0.010,
                "missing_intervals": +0.020,
                "hot_cold": +0.010,
                "periodicity": +0.010,
                "regression_trend": +0.010,
                "moving_average": +0.010,
                "attraction_effect": +0.010,
                "distribution": +0.010,
                "adjacent_correlation": +0.010
            }
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥æ€§èƒ½ã«åŸºã¥ãå¾®èª¿æ•´
        if 1 in pattern_stats and pattern_stats[1]['total_predictions'] > 0:
            pattern1_performance = pattern_stats[1]['average_hit_rate']
            if pattern1_performance < 0.15:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³1ã®æ€§èƒ½ãŒæ‚ªã„å ´åˆã€åŸºæœ¬ç‰¹å¾´é‡ã‚’å¼·åŒ–
                adjustments["total_appearances"] += 0.005
                adjustments["recent_appearances"] += 0.005
        
        return adjustments, overall_hit_rate
    
    def apply_weight_adjustments(self, adjustments):
        """é‡ã¿èª¿æ•´ã‚’é©ç”¨"""
        print("ğŸ§  æ”¹è‰¯ç‰ˆTotoä¸¸ãã‚“ å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ")
        print("\n" + "=" * 40)
        
        # ç¾åœ¨ã®é‡ã¿ã‚’è¡¨ç¤º
        print("ğŸ“Š èª¿æ•´å‰ã®é‡ã¿è¨­å®š:")
        print("-" * 40)
        for feature, weight in self.weights.items():
            print(f"  {feature}: {weight:.3f}")
        
        # èª¿æ•´ã‚’é©ç”¨
        print(f"\nğŸ“ˆ é‡ã¿èª¿æ•´:")
        print("-" * 40)
        for feature, adjustment in adjustments.items():
            old_weight = self.weights[feature]
            new_weight = max(0.01, old_weight + adjustment)  # æœ€å°0.01ã‚’ä¿è¨¼
            self.weights[feature] = new_weight
            
            change = "+" if adjustment >= 0 else ""
            print(f"  {feature}: {old_weight:.3f} â†’ {new_weight:.3f} ({change}{adjustment:.3f})")
        
        # é‡ã¿ã®æ­£è¦åŒ–
        total_weight = sum(self.weights.values())
        for feature in self.weights:
            self.weights[feature] /= total_weight
        
        print(f"\nâš–ï¸ èª¿æ•´å¾Œã®é‡ã¿è¨­å®š:")
        print("-" * 40)
        for feature, weight in self.weights.items():
            print(f"  {feature}: {weight:.3f}")
        
        # é‡ã¿ã‚’ä¿å­˜
        with open('weights.json', 'w', encoding='utf-8') as file:
            json.dump(self.weights, file, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… é‡ã¿èª¿æ•´å®Œäº†")
        print("=" * 40)
    
    def generate_learning_report(self):
        """å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        pattern_stats = self.analyze_pattern_performance()
        adjustments, overall_hit_rate = self.calculate_weight_adjustments()
        
        print(f"\nğŸ“Š å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 40)
        print(f"ğŸ¯ å…¨ä½“å¹³å‡çš„ä¸­ç‡: {overall_hit_rate:.1%}")
        
        print(f"\nğŸ“ˆ ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥æ€§èƒ½:")
        print("-" * 40)
        for pattern_num in sorted(pattern_stats.keys()):
            stats = pattern_stats[pattern_num]
            if stats['total_predictions'] > 0:
                print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³{pattern_num}: {stats['average_hit_rate']:.1%} "
                      f"({stats['total_predictions']}å›)")
        
        print(f"\nğŸ”§ æ¨å¥¨èª¿æ•´:")
        print("-" * 40)
        for feature, adjustment in adjustments.items():
            if adjustment != 0:
                direction = "å¼·åŒ–" if adjustment > 0 else "å¼±åŒ–"
                print(f"  {feature}: {direction} ({adjustment:+.3f})")
        
        return {
            'overall_hit_rate': overall_hit_rate,
            'pattern_stats': pattern_stats,
            'adjustments': adjustments
        }
    
    def learn(self):
        """å­¦ç¿’å®Ÿè¡Œ"""
        print("ğŸ§  æ”¹è‰¯ç‰ˆTotoä¸¸ãã‚“ å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 50)
        
        if not self.evaluation_data:
            print("âš ï¸ è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        print(f"ğŸ“Š åˆ†æå¯¾è±¡: {len(self.evaluation_data)}å›åˆ†ã®ãƒ‡ãƒ¼ã‚¿")
        
        # å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self.generate_learning_report()
        
        # é‡ã¿èª¿æ•´
        adjustments, overall_hit_rate = self.calculate_weight_adjustments()
        self.apply_weight_adjustments(adjustments)
        
        # æ”¹å–„ææ¡ˆ
        print(f"\nğŸ’¡ æ”¹å–„ææ¡ˆ:")
        print("-" * 40)
        
        if overall_hit_rate < 0.15:
            print("  ğŸ”´ çš„ä¸­ç‡ãŒä½ã„ãŸã‚ã€å¤§å¹…ãªèª¿æ•´ã‚’è¡Œã„ã¾ã—ãŸ")
            print("  ğŸ“ æ¨å¥¨: ã‚ˆã‚Šå¤šãã®çµ±è¨ˆç‰¹å¾´é‡ã®è¿½åŠ ã‚’æ¤œè¨")
        elif overall_hit_rate < 0.25:
            print("  ğŸŸ¡ çš„ä¸­ç‡ãŒä¸­ç¨‹åº¦ã®ãŸã‚ã€ä¸­ç¨‹åº¦ã®èª¿æ•´ã‚’è¡Œã„ã¾ã—ãŸ")
            print("  ğŸ“ æ¨å¥¨: ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ”¹å–„ã‚’æ¤œè¨")
        else:
            print("  ğŸŸ¢ çš„ä¸­ç‡ãŒè‰¯å¥½ãªãŸã‚ã€å¾®èª¿æ•´ã®ã¿è¡Œã„ã¾ã—ãŸ")
            print("  ğŸ“ æ¨å¥¨: ç¾åœ¨ã®è¨­å®šã‚’ç¶­æŒ")
        
        print(f"\nğŸ¯ å­¦ç¿’å®Œäº†ï¼æ¬¡å›ã®äºˆæ¸¬ã‹ã‚‰æ”¹å–„ã•ã‚ŒãŸé‡ã¿ãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚")
        print("=" * 50)

if __name__ == "__main__":
    learner = ImprovedLearningSystem()
    learner.learn() 