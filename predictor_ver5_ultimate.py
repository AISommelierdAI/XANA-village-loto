#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ToToã€‡ãã‚“ Ver.5 Ultimate - ç©¶æ¥µå®Œæˆç‰ˆ
AIé§†å‹•ã®é«˜åº¦ãªäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
"""

import csv
import json
import random
import math
from collections import Counter, defaultdict
from datetime import datetime, timedelta
import os

class TotoVer5Ultimate:
    def __init__(self, csv_file='totomaru.csv'):
        self.csv_file = csv_file
        self.results_dir = 'results'
        self.ensure_results_dir()
        self.learning_history = self.load_learning_history()
        self.ai_weights = self.initialize_ai_weights()
        
    def ensure_results_dir(self):
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)
    
    def initialize_ai_weights(self):
        """AIé‡ã¿ã®åˆæœŸåŒ–"""
        return {
            'range_balance': 0.25,
            'consecutive_pattern': 0.20,
            'frequency_analysis': 0.15,
            'temporal_trend': 0.15,
            'statistical_optimization': 0.15,
            'learning_adaptation': 0.10
        }
    
    def load_learning_history(self):
        """é«˜åº¦ãªå­¦ç¿’å±¥æ­´ã®èª­ã¿è¾¼ã¿ã¨åˆ†æ"""
        history = {
            'recent_hits': [],
            'range_performance': {'low': [], 'mid': [], 'high': []},
            'consecutive_patterns': [],
            'bonus_patterns': [],
            'failed_predictions': [],
            'success_patterns': [],
            'temporal_cycles': [],
            'statistical_trends': []
        }
        
        # æœ€è¿‘ã®è©•ä¾¡ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å­¦ç¿’
        evaluation_files = [f for f in os.listdir('.') if f.startswith('evaluation_') and f.endswith('.json')]
        for file in sorted(evaluation_files)[-15:]:  # æœ€è¿‘15å›åˆ†
            try:
                with open(file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    actual = data['actual_result']
                    
                    # ç¯„å›²åˆ¥çš„ä¸­ç‡ã®åˆ†æ
                    for num in actual:
                        if 1 <= num <= 20:
                            history['range_performance']['low'].append(num)
                        elif 21 <= num <= 40:
                            history['range_performance']['mid'].append(num)
                        else:
                            history['range_performance']['high'].append(num)
                    
                    # é€£ç¶šæ•°å­—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                    sorted_nums = sorted(actual)
                    for i in range(len(sorted_nums) - 1):
                        if sorted_nums[i+1] - sorted_nums[i] == 1:
                            history['consecutive_patterns'].append((sorted_nums[i], sorted_nums[i+1]))
                    
                    # ãƒœãƒ¼ãƒŠã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                    if 'bonus' in data:
                        history['bonus_patterns'].append(data['bonus'])
                    
                    # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¨˜éŒ²
                    if 'hits' in data and data['hits'] > 0:
                        history['success_patterns'].append({
                            'hits': data['hits'],
                            'numbers': actual,
                            'confidence': data.get('confidence', 0)
                        })
                        
            except Exception as e:
                continue
        
        return history
    
    def load_data(self):
        """CSVãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        data = []
        try:
            with open(self.csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    try:
                        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã«åˆã‚ã›ã¦ä¿®æ­£
                        numbers = []
                        for i in range(1, 7):
                            key = f'Number{i}'
                            if key in row and row[key] is not None:
                                numbers.append(int(row[key]))
                            else:
                                print(f"åˆ— {key} ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€å€¤ãŒNoneã§ã™")
                                continue
                        
                        if len(numbers) != 6:
                            continue
                        
                        if 'Additional' in row and row['Additional'] is not None:
                            bonus = int(row['Additional'])
                        else:
                            bonus = 0
                            
                        if 'DrawDate' in row:
                            date = row['DrawDate']
                        else:
                            date = "unknown"
                            
                        data.append({
                            'date': date,
                            'numbers': numbers,
                            'bonus': bonus
                        })
                    except (ValueError, KeyError) as e:
                        continue
        except Exception as e:
            print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
        return data
    
    def analyze_ai_patterns(self, data):
        """AIé§†å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆé«˜åº¦ãªæ•°å­¦çš„æ‰‹æ³•è¿½åŠ ï¼‰"""
        patterns = {
            'frequency_matrix': defaultdict(Counter),
            'temporal_cycles': defaultdict(list),
            'statistical_correlations': {},
            'pattern_evolution': [],
            'fourier_analysis': {},
            'chaos_analysis': {},
            'bayesian_probabilities': {},
            'theoretical_distribution': {},
            'statistical_tests': {},
            'monte_carlo_simulation': {},
            'markov_chain_analysis': {},
            'enhanced_time_series': {}
        }
        
        # é »åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹åˆ†æ
        for i, draw in enumerate(data[-30:]):
            for num in draw['numbers']:
                patterns['frequency_matrix'][num][i] += 1
        
        # æ™‚é–“çš„ã‚µã‚¤ã‚¯ãƒ«åˆ†æ
        for i, draw in enumerate(data[-20:]):
            week_day = i % 7
            patterns['temporal_cycles'][week_day].extend(draw['numbers'])
        
        # çµ±è¨ˆçš„ç›¸é–¢åˆ†æ
        all_numbers = []
        for draw in data[-20:]:
            all_numbers.extend(draw['numbers'])
        
        number_freq = Counter(all_numbers)
        patterns['statistical_correlations'] = {
            'most_frequent': number_freq.most_common(10),
            'least_frequent': sorted(number_freq.items(), key=lambda x: x[1])[:10]
        }
        
        # ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã«ã‚ˆã‚‹å‘¨æœŸæ€§åˆ†æ
        patterns['fourier_analysis'] = self.analyze_fourier_patterns(data)
        
        # ã‚«ã‚ªã‚¹ç†è«–ã«ã‚ˆã‚‹äºˆæ¸¬ä¸å¯èƒ½æ€§åˆ†æ
        patterns['chaos_analysis'] = self.analyze_chaos_patterns(data)
        
        # ãƒ™ã‚¤ã‚ºçµ±è¨ˆã«ã‚ˆã‚‹ç¢ºç‡æ›´æ–°
        patterns['bayesian_probabilities'] = self.analyze_bayesian_probabilities(data)
        
        # ç†è«–çš„ç¢ºç‡åˆ†å¸ƒåˆ†æ
        patterns['theoretical_distribution'] = self.analyze_theoretical_probability(data)
        
        # çµ±è¨ˆçš„æ¤œå®šã«ã‚ˆã‚‹æœ‰æ„æ€§ç¢ºèª
        patterns['statistical_tests'] = self.perform_statistical_tests(data)
        
        # ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        patterns['monte_carlo_simulation'] = self.perform_monte_carlo_simulation(data)
        
        # ãƒãƒ«ã‚³ãƒ•é€£é–åˆ†æ
        patterns['markov_chain_analysis'] = self.analyze_markov_chains(data)
        
        # å¼·åŒ–ã•ã‚ŒãŸæ™‚ç³»åˆ—åˆ†æ
        patterns['enhanced_time_series'] = self.enhanced_time_series_analysis(data)
        
        return patterns
    
    def analyze_fourier_patterns(self, data):
        """ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã«ã‚ˆã‚‹å‘¨æœŸæ€§åˆ†æ"""
        try:
            import numpy as np
            
            # å„æ•°å­—ã®å‡ºç¾æ™‚ç³»åˆ—ã‚’ä½œæˆ
            time_series = {}
            for num in range(1, 50):
                time_series[num] = []
                for i, draw in enumerate(data[-50:]):
                    time_series[num].append(1 if num in draw['numbers'] else 0)
            
            # ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã§å‘¨æœŸæ€§ã‚’æ¤œå‡º
            fourier_results = {}
            for num, series in time_series.items():
                if len(series) > 1:
                    fft = np.fft.fft(series)
                    power_spectrum = np.abs(fft) ** 2
                    # ä¸»è¦ãªå‘¨æ³¢æ•°æˆåˆ†ã‚’æŠ½å‡º
                    dominant_freq = np.argmax(power_spectrum[1:len(power_spectrum)//2]) + 1
                    fourier_results[num] = {
                        'dominant_frequency': dominant_freq,
                        'power': np.max(power_spectrum),
                        'periodicity_score': np.sum(power_spectrum[1:]) / len(power_spectrum)
                    }
            
            return fourier_results
        except ImportError:
            return {'error': 'numpy not available'}
    
    def analyze_chaos_patterns(self, data):
        """ã‚«ã‚ªã‚¹ç†è«–ã«ã‚ˆã‚‹äºˆæ¸¬ä¸å¯èƒ½æ€§åˆ†æ"""
        chaos_analysis = {
            'lyapunov_exponents': {},
            'fractal_dimensions': {},
            'entropy_analysis': {}
        }
        
        # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åˆ†æï¼ˆãƒ©ãƒ³ãƒ€ãƒ æ€§ã®æ¸¬å®šï¼‰
        for i in range(1, 50):
            appearances = [1 if i in draw['numbers'] else 0 for draw in data[-30:]]
            if sum(appearances) > 0:
                p = sum(appearances) / len(appearances)
                if p > 0 and p < 1:
                    entropy = -p * math.log2(p) - (1-p) * math.log2(1-p)
                    chaos_analysis['entropy_analysis'][i] = entropy
        
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒã®ç°¡æ˜“è¨ˆç®—
        for draw in data[-20:]:
            sorted_nums = sorted(draw['numbers'])
            gaps = [sorted_nums[i+1] - sorted_nums[i] for i in range(len(sorted_nums)-1)]
            if gaps:
                avg_gap = sum(gaps) / len(gaps)
                chaos_analysis['fractal_dimensions'][tuple(sorted_nums)] = avg_gap
        
        return chaos_analysis
    
    def analyze_bayesian_probabilities(self, data):
        """ãƒ™ã‚¤ã‚ºçµ±è¨ˆã«ã‚ˆã‚‹ç¢ºç‡æ›´æ–°"""
        bayesian_results = {}
        
        # äº‹å‰ç¢ºç‡ï¼ˆç†è«–çš„ç¢ºç‡ï¼‰
        prior_prob = 1/49
        
        for num in range(1, 50):
            # äº‹å¾Œç¢ºç‡ã®è¨ˆç®—
            appearances = sum(1 for draw in data[-20:] if num in draw['numbers'])
            total_draws = len(data[-20:])
            
            if total_draws > 0:
                likelihood = appearances / total_draws
                # ãƒ™ã‚¤ã‚ºæ›´æ–°ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                posterior_prob = (likelihood * prior_prob) / (likelihood * prior_prob + (1-likelihood) * (1-prior_prob))
                bayesian_results[num] = {
                    'prior_probability': prior_prob,
                    'likelihood': likelihood,
                    'posterior_probability': posterior_prob,
                    'appearances': appearances
                }
        
        return bayesian_results
    
    def analyze_theoretical_probability(self, data):
        """ç†è«–çš„ç¢ºç‡åˆ†å¸ƒåˆ†æ"""
        theoretical_analysis = {
            'expected_frequencies': {},
            'deviation_analysis': {},
            'randomness_tests': {}
        }
        
        # ç†è«–çš„æœŸå¾…å€¤
        total_draws = len(data)
        expected_freq = (6 * total_draws) / 49
        
        # å®Ÿéš›ã®é »åº¦ã¨ç†è«–å€¤ã®æ¯”è¼ƒ
        actual_freq = Counter()
        for draw in data:
            for num in draw['numbers']:
                actual_freq[num] += 1
        
        for num in range(1, 50):
            actual = actual_freq.get(num, 0)
            deviation = (actual - expected_freq) / expected_freq
            theoretical_analysis['expected_frequencies'][num] = expected_freq
            theoretical_analysis['deviation_analysis'][num] = {
                'actual': actual,
                'expected': expected_freq,
                'deviation': deviation,
                'z_score': deviation / math.sqrt(expected_freq) if expected_freq > 0 else 0
            }
        
        return theoretical_analysis
    
    def perform_statistical_tests(self, data):
        """çµ±è¨ˆçš„æ¤œå®šã«ã‚ˆã‚‹æœ‰æ„æ€§ç¢ºèª"""
        statistical_tests = {
            'chi_square_test': {},
            'kolmogorov_smirnov_test': {},
            'randomness_indicators': {}
        }
        
        # ã‚«ã‚¤äºŒä¹—æ¤œå®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
        observed_freq = Counter()
        for draw in data[-30:]:
            for num in draw['numbers']:
                observed_freq[num] += 1
        
        expected_freq = (6 * 30) / 49
        chi_square = 0
        
        for num in range(1, 50):
            observed = observed_freq.get(num, 0)
            chi_square += ((observed - expected_freq) ** 2) / expected_freq
        
        statistical_tests['chi_square_test'] = {
            'chi_square_statistic': chi_square,
            'degrees_of_freedom': 48,
            'p_value_estimate': self.estimate_p_value(chi_square, 48)
        }
        
        # ãƒ©ãƒ³ãƒ€ãƒ æ€§æŒ‡æ¨™
        consecutive_counts = []
        for draw in data[-20:]:
            sorted_nums = sorted(draw['numbers'])
            consecutive = sum(1 for i in range(len(sorted_nums)-1) if sorted_nums[i+1] - sorted_nums[i] == 1)
            consecutive_counts.append(consecutive)
        
        statistical_tests['randomness_indicators'] = {
            'avg_consecutive': sum(consecutive_counts) / len(consecutive_counts),
            'consecutive_variance': self.calculate_variance(consecutive_counts),
            'runs_test': self.perform_runs_test(data[-20:])
        }
        
        return statistical_tests
    
    def estimate_p_value(self, chi_square, df):
        """ã‚«ã‚¤äºŒä¹—æ¤œå®šã®på€¤æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # ç°¡æ˜“çš„ãªpå€¤æ¨å®š
        if chi_square < df:
            return 0.5
        elif chi_square < df * 1.5:
            return 0.1
        elif chi_square < df * 2:
            return 0.05
        else:
            return 0.01
    
    def calculate_variance(self, values):
        """åˆ†æ•£ã®è¨ˆç®—"""
        if not values:
            return 0
        mean = sum(values) / len(values)
        return sum((x - mean) ** 2 for x in values) / len(values)
    
    def perform_runs_test(self, data):
        """ãƒ©ãƒ³ã®æ¤œå®šã«ã‚ˆã‚‹ãƒ©ãƒ³ãƒ€ãƒ æ€§ç¢ºèª"""
        # æœ€è¿‘20å›ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ©ãƒ³ã®æ¤œå®š
        recent_data = data[-20:]
        runs_data = []
        
        for draw in recent_data:
            sorted_nums = sorted(draw['numbers'])
            # é€£ç¶šæ€§ã®åˆ¤å®š
            for i in range(len(sorted_nums) - 1):
                if sorted_nums[i+1] - sorted_nums[i] == 1:
                    runs_data.append(1)  # é€£ç¶š
                else:
                    runs_data.append(0)  # éé€£ç¶š
        
        if len(runs_data) > 1:
            runs = 1
            for i in range(1, len(runs_data)):
                if runs_data[i] != runs_data[i-1]:
                    runs += 1
            
            # ç†è«–çš„æœŸå¾…å€¤
            n1 = sum(runs_data)
            n2 = len(runs_data) - n1
            expected_runs = 1 + (2 * n1 * n2) / (n1 + n2)
            variance = (2 * n1 * n2 * (2 * n1 * n2 - n1 - n2)) / ((n1 + n2) ** 2 * (n1 + n2 - 1))
            
            if variance > 0:
                z_score = (runs - expected_runs) / math.sqrt(variance)
                p_value = 2 * (1 - self.estimate_p_value(abs(z_score), 1))
            else:
                z_score = 0
                p_value = 1.0
            
            return {
                'runs_count': runs,
                'expected_runs': expected_runs,
                'z_score': z_score,
                'p_value': p_value,
                'runs_ratio': runs / expected_runs if expected_runs > 0 else 1.0
            }
        
        return {'runs_count': 0, 'expected_runs': 0, 'z_score': 0, 'p_value': 1.0, 'runs_ratio': 1.0}
    
    def perform_monte_carlo_simulation(self, data):
        """ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹äºˆæ¸¬"""
        monte_carlo_results = {
            'simulation_results': [],
            'probability_distribution': {},
            'confidence_intervals': {},
            'pattern_probabilities': {}
        }
        
        # 1000å›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        num_simulations = 1000
        simulation_results = []
        
        for _ in range(num_simulations):
            # éå»ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç¢ºç‡åˆ†å¸ƒã‚’æ§‹ç¯‰
            number_freq = Counter()
            for draw in data[-50:]:  # æœ€è¿‘50å›åˆ†
                for num in draw['numbers']:
                    number_freq[num] += 1
            
            # é‡ã¿ä»˜ããƒ©ãƒ³ãƒ€ãƒ é¸æŠã§6å€‹ã®æ•°å­—ã‚’ç”Ÿæˆ
            total_weight = sum(number_freq.values())
            if total_weight > 0:
                weights = [number_freq.get(i, 1) for i in range(1, 50)]
                simulated_numbers = []
                
                # é‡è¤‡ãªã—ã§6å€‹é¸æŠ
                available_numbers = list(range(1, 50))
                for _ in range(6):
                    if available_numbers:
                        # é‡ã¿ä»˜ããƒ©ãƒ³ãƒ€ãƒ é¸æŠ
                        chosen = random.choices(available_numbers, 
                                              weights=[weights[i-1] for i in available_numbers])[0]
                        simulated_numbers.append(chosen)
                        available_numbers.remove(chosen)
                
                simulation_results.append(sorted(simulated_numbers))
        
        # çµæœã®åˆ†æ
        pattern_freq = Counter()
        number_freq_sim = Counter()
        
        for result in simulation_results:
            pattern_freq[tuple(result)] += 1
            for num in result:
                number_freq_sim[num] += 1
        
        # ç¢ºç‡åˆ†å¸ƒã®è¨ˆç®—
        for num in range(1, 50):
            prob = number_freq_sim.get(num, 0) / num_simulations
            monte_carlo_results['probability_distribution'][num] = prob
        
        # ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ï¼ˆä¸Šä½10%ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        top_patterns = pattern_freq.most_common(10)
        monte_carlo_results['confidence_intervals'] = {
            'top_patterns': [(list(pattern), freq/num_simulations) for pattern, freq in top_patterns]
        }
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ç¢ºç‡ã®è¨ˆç®—
        for pattern, freq in pattern_freq.items():
            if freq >= 2:  # 2å›ä»¥ä¸Šå‡ºç¾ã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿
                monte_carlo_results['pattern_probabilities'][tuple(pattern)] = freq / num_simulations
        
        return monte_carlo_results
    
    def analyze_markov_chains(self, data):
        """ãƒãƒ«ã‚³ãƒ•é€£é–åˆ†æã«ã‚ˆã‚‹é·ç§»ç¢ºç‡ã®è¨ˆç®—"""
        markov_results = {
            'transition_matrix': {},
            'steady_state_probabilities': {},
            'pattern_transitions': {},
            'number_sequences': {}
        }
        
        # é·ç§»è¡Œåˆ—ã®æ§‹ç¯‰
        transition_counts = defaultdict(lambda: defaultdict(int))
        total_transitions = defaultdict(int)
        
        for draw in data[-100:]:  # æœ€è¿‘100å›åˆ†
            sorted_nums = sorted(draw['numbers'])
            
            # æ•°å­—é–“ã®é·ç§»ã‚’è¨˜éŒ²
            for i in range(len(sorted_nums) - 1):
                current = sorted_nums[i]
                next_num = sorted_nums[i + 1]
                transition_counts[current][next_num] += 1
                total_transitions[current] += 1
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³é–“ã®é·ç§»ã‚’è¨˜éŒ²
            pattern = tuple(sorted_nums)
            if 'previous_pattern' in locals():
                if 'previous_pattern' not in transition_counts:
                    transition_counts['previous_pattern'] = defaultdict(int)
                transition_counts['previous_pattern'][pattern] += 1
                total_transitions['previous_pattern'] += 1
            previous_pattern = pattern
        
        # é·ç§»ç¢ºç‡ã®è¨ˆç®—
        for current, transitions in transition_counts.items():
            if total_transitions[current] > 0:
                markov_results['transition_matrix'][current] = {
                    next_num: count / total_transitions[current]
                    for next_num, count in transitions.items()
                }
        
        # å®šå¸¸çŠ¶æ…‹ç¢ºç‡ã®è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        steady_state = {}
        total_appearances = Counter()
        
        for draw in data[-50:]:
            for num in draw['numbers']:
                total_appearances[num] += 1
        
        total_draws = len(data[-50:])
        for num in range(1, 50):
            steady_state[num] = total_appearances.get(num, 0) / (total_draws * 6)
        
        markov_results['steady_state_probabilities'] = steady_state
        
        # æ•°å­—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®åˆ†æ
        markov_results['number_sequences'] = Counter()
        for draw in data[-30:]:
            sorted_nums = sorted(draw['numbers'])
            sequence_key = tuple(sorted_nums[i+1] - sorted_nums[i] for i in range(len(sorted_nums)-1))
            markov_results['number_sequences'][sequence_key] += 1
        
        return markov_results
    
    def enhanced_time_series_analysis(self, data):
        """å¼·åŒ–ã•ã‚ŒãŸæ™‚ç³»åˆ—åˆ†æ"""
        time_series_results = {
            'trend_analysis': {},
            'seasonal_patterns': {},
            'autocorrelation': {},
            'volatility_analysis': {},
            'momentum_indicators': {}
        }
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        for num in range(1, 50):
            appearances = []
            for i, draw in enumerate(data[-30:]):
                appearances.append(1 if num in draw['numbers'] else 0)
            
            if len(appearances) > 1:
                # ç·šå½¢ãƒˆãƒ¬ãƒ³ãƒ‰ã®è¨ˆç®—
                x = list(range(len(appearances)))
                y = appearances
                
                # æœ€å°äºŒä¹—æ³•ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
                n = len(x)
                sum_x = sum(x)
                sum_y = sum(y)
                sum_xy = sum(x[i] * y[i] for i in range(n))
                sum_x2 = sum(x[i] ** 2 for i in range(n))
                
                if n * sum_x2 - sum_x ** 2 != 0:
                    slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x ** 2)
                    intercept = (sum_y - slope * sum_x) / n
                    
                    time_series_results['trend_analysis'][num] = {
                        'slope': slope,
                        'intercept': intercept,
                        'trend_strength': abs(slope),
                        'trend_direction': 'increasing' if slope > 0 else 'decreasing'
                    }
        
        # å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
        seasonal_patterns = defaultdict(lambda: defaultdict(int))
        for i, draw in enumerate(data[-60:]):  # æœ€è¿‘60å›åˆ†
            week_of_year = i % 52  # 52é€±ã§å¾ªç’°
            for num in draw['numbers']:
                seasonal_patterns[week_of_year][num] += 1
        
        time_series_results['seasonal_patterns'] = dict(seasonal_patterns)
        
        # è‡ªå·±ç›¸é–¢åˆ†æ
        for num in range(1, 50):
            appearances = [1 if num in draw['numbers'] else 0 for draw in data[-20:]]
            if len(appearances) > 5:
                # ãƒ©ã‚°1ã®è‡ªå·±ç›¸é–¢
                autocorr = 0
                for i in range(len(appearances) - 1):
                    autocorr += appearances[i] * appearances[i + 1]
                
                if len(appearances) > 1:
                    autocorr /= (len(appearances) - 1)
                    time_series_results['autocorrelation'][num] = autocorr
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ
        volatility_data = []
        for draw in data[-20:]:
            sorted_nums = sorted(draw['numbers'])
            # æ•°å­—é–“ã®åˆ†æ•£ã‚’è¨ˆç®—
            mean_num = sum(sorted_nums) / len(sorted_nums)
            variance = sum((num - mean_num) ** 2 for num in sorted_nums) / len(sorted_nums)
            volatility_data.append(math.sqrt(variance))
        
        if volatility_data:
            time_series_results['volatility_analysis'] = {
                'mean_volatility': sum(volatility_data) / len(volatility_data),
                'volatility_trend': 'increasing' if len(volatility_data) > 1 and volatility_data[-1] > volatility_data[0] else 'decreasing'
            }
        
        # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ æŒ‡æ¨™
        momentum_indicators = {}
        for num in range(1, 50):
            recent_appearances = sum(1 for draw in data[-5:] if num in draw['numbers'])
            older_appearances = sum(1 for draw in data[-10:-5] if num in draw['numbers'])
            
            momentum = recent_appearances - older_appearances
            momentum_indicators[num] = {
                'momentum': momentum,
                'momentum_strength': abs(momentum),
                'momentum_direction': 'positive' if momentum > 0 else 'negative'
            }
        
        time_series_results['momentum_indicators'] = momentum_indicators
        
        return time_series_results
    
    def analyze_range_trends_advanced(self, data):
        """é«˜åº¦ãªç¯„å›²åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        range_analysis = {
            'low': {'counts': Counter(), 'trends': [], 'cycles': []},
            'mid': {'counts': Counter(), 'trends': [], 'cycles': []},
            'high': {'counts': Counter(), 'trends': [], 'cycles': []}
        }
        
        for i, draw in enumerate(data[-25:]):
            low_count = mid_count = high_count = 0
            
            for num in draw['numbers']:
                if 1 <= num <= 20:
                    range_analysis['low']['counts'][num] += 1
                    low_count += 1
                elif 21 <= num <= 40:
                    range_analysis['mid']['counts'][num] += 1
                    mid_count += 1
                else:
                    range_analysis['high']['counts'][num] += 1
                    high_count += 1
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰è¨˜éŒ²
            range_analysis['low']['trends'].append(low_count)
            range_analysis['mid']['trends'].append(mid_count)
            range_analysis['high']['trends'].append(high_count)
        
        return range_analysis
    
    def analyze_consecutive_patterns_advanced(self, data):
        """é«˜åº¦ãªé€£ç¶šæ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        consecutive_analysis = {
            'immediate_consecutive': Counter(),
            'near_consecutive': Counter(),
            'consecutive_groups': [],
            'consecutive_trends': []
        }
        
        for draw in data[-30:]:
            sorted_nums = sorted(draw['numbers'])
            consecutive_count = 0
            
            for i in range(len(sorted_nums) - 1):
                diff = sorted_nums[i+1] - sorted_nums[i]
                
                if diff == 1:
                    consecutive_analysis['immediate_consecutive'][(sorted_nums[i], sorted_nums[i+1])] += 1
                    consecutive_count += 1
                elif diff <= 3:
                    consecutive_analysis['near_consecutive'][diff] += 1
            
            consecutive_analysis['consecutive_trends'].append(consecutive_count)
        
        return consecutive_analysis
    
    def calculate_ai_confidence(self, pattern, ai_patterns, range_analysis, consecutive_analysis):
        """AIé§†å‹•ä¿¡é ¼åº¦è¨ˆç®—"""
        confidence = 50.0  # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦
        
        # ç¯„å›²ãƒãƒ©ãƒ³ã‚¹è©•ä¾¡
        low_count = len([n for n in pattern if 1 <= n <= 20])
        mid_count = len([n for n in pattern if 21 <= n <= 40])
        high_count = len([n for n in pattern if 41 <= n <= 49])
        
        balance_score = 1.0 - abs(low_count - mid_count) / 6.0
        confidence += balance_score * 15.0
        
        # é »åº¦åˆ†æè©•ä¾¡
        freq_score = 0
        for num in pattern:
            freq = ai_patterns['statistical_correlations']['most_frequent']
            for rank, (freq_num, count) in enumerate(freq):
                if num == freq_num:
                    freq_score += (10 - rank) / 10.0
                    break
        confidence += freq_score * 10.0
        
        # é€£ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³è©•ä¾¡
        consecutive_score = 0
        sorted_pattern = sorted(pattern)
        for i in range(len(sorted_pattern) - 1):
            diff = sorted_pattern[i+1] - sorted_pattern[i]
            if diff == 1:
                consecutive_score += 5.0
            elif diff <= 3:
                consecutive_score += 2.0
        confidence += consecutive_score
        
        # å­¦ç¿’å±¥æ­´è©•ä¾¡
        learning_score = 0
        for success in self.learning_history['success_patterns']:
            common_hits = len(set(pattern) & set(success['numbers']))
            if common_hits >= 2:
                learning_score += success['hits'] * 2.0
        confidence += min(learning_score, 10.0)
        
        return min(confidence, 95.0)
    
    def predict_range_specific_ai(self, range_type, range_analysis, target_count=2):
        """AIé§†å‹•ç¯„å›²åˆ¥äºˆæ¸¬ï¼ˆå›ºå®šåŒ–é˜²æ­¢ï¼‰"""
        if range_type == 'low':
            candidates = list(range(1, 21))
        elif range_type == 'mid':
            candidates = list(range(21, 41))
        else:
            candidates = list(range(41, 50))
        
        # AIé‡ã¿ä»˜ãã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆå›ºå®šåŒ–é˜²æ­¢å¼·åŒ–ï¼‰
        scores = {}
        for num in candidates:
            freq = range_analysis[range_type]['counts'].get(num, 0)
            
            # åŸºæœ¬ã‚¹ã‚³ã‚¢ï¼ˆãƒ©ãƒ³ãƒ€ãƒ è¦ç´ å¼·åŒ–ï¼‰
            base_score = freq * 2.0 + random.random() * 5.0
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            recent_trend = range_analysis[range_type]['trends'][-5:] if range_analysis[range_type]['trends'] else []
            trend_bonus = sum(recent_trend) / len(recent_trend) if recent_trend else 0
            
            # å­¦ç¿’å±¥æ­´ãƒœãƒ¼ãƒŠã‚¹
            learning_bonus = 0
            for success in self.learning_history['success_patterns']:
                if num in success['numbers']:
                    learning_bonus += success['hits'] * 0.5
            
            # æ™‚é–“çš„ãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ï¼ˆå›ºå®šåŒ–é˜²æ­¢ï¼‰
            time_random = random.random() * 10.0
            
            # æœ€çµ‚ã‚¹ã‚³ã‚¢ï¼ˆã‚ˆã‚Šå¤šæ§˜åŒ–ï¼‰
            scores[num] = base_score + trend_bonus + learning_bonus + time_random
        
        # ä¸Šä½æ•°å­—ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ é¸æŠï¼ˆå›ºå®šåŒ–é˜²æ­¢ï¼‰
        sorted_numbers = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        top_candidates = sorted_numbers[:min(target_count * 3, len(sorted_numbers))]
        
        # é‡ã¿ä»˜ããƒ©ãƒ³ãƒ€ãƒ é¸æŠ
        weights = [score for _, score in top_candidates]
        selected = []
        
        for _ in range(target_count):
            if not top_candidates:
                break
            
            # ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
            chosen_idx = random.choices(range(len(top_candidates)), weights=weights)[0]
            selected.append(top_candidates[chosen_idx][0])
            
            # é¸æŠã•ã‚ŒãŸå€™è£œã‚’å‰Šé™¤ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
            top_candidates.pop(chosen_idx)
            weights.pop(chosen_idx)
        
        return selected
    
    def predict_consecutive_ai(self, base_numbers, consecutive_analysis):
        """AIé§†å‹•é€£ç¶šæ•°å­—äºˆæ¸¬"""
        candidates = []
        
        # å³åº§é€£ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³
        immediate_consecutive = consecutive_analysis['immediate_consecutive']
        for num in base_numbers:
            # å‰å¾Œã®é€£ç¶šæ•°å­—ã‚’ãƒã‚§ãƒƒã‚¯
            if (num, num + 1) in immediate_consecutive and num + 1 <= 49:
                candidates.append(num + 1)
            if (num - 1, num) in immediate_consecutive and num - 1 >= 1:
                candidates.append(num - 1)
        
        # è¿‘æ¥é€£ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³
        near_consecutive = consecutive_analysis['near_consecutive']
        if near_consecutive.get(2, 0) > 3:  # å·®2ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒé »ç¹
            for num in base_numbers:
                if num + 2 <= 49 and num + 2 not in base_numbers:
                    candidates.append(num + 2)
                if num - 2 >= 1 and num - 2 not in base_numbers:
                    candidates.append(num - 2)
        
        return list(set(candidates))[:3]  # é‡è¤‡é™¤å»ã—ã¦æœ€å¤§3å€‹
    
    def predict_bonus_ai(self, data, ai_patterns):
        """AIé§†å‹•ãƒœãƒ¼ãƒŠã‚¹äºˆæ¸¬"""
        bonus_freq = Counter()
        
        for draw in data[-20:]:
            bonus_freq[draw['bonus']] += 1
        
        # çµ±è¨ˆçš„ç›¸é–¢ã‚’è€ƒæ…®
        most_frequent = ai_patterns['statistical_correlations']['most_frequent']
        bonus_candidates = []
        
        for num, freq in most_frequent[:15]:  # ä¸Šä½15å€‹
            if bonus_freq.get(num, 0) > 0:
                bonus_candidates.append((num, freq + bonus_freq[num] * 2))
        
        if bonus_candidates:
            sorted_bonus = sorted(bonus_candidates, key=lambda x: x[1], reverse=True)
            return sorted_bonus[0][0]
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return random.randint(1, 49)
    
    def generate_ultimate_patterns(self, data):
        """ç©¶æ¥µãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆï¼ˆæ–°åˆ†ææ‰‹æ³•çµ±åˆç‰ˆï¼‰"""
        ai_patterns = self.analyze_ai_patterns(data)
        range_analysis = self.analyze_range_trends_advanced(data)
        consecutive_analysis = self.analyze_consecutive_patterns_advanced(data)
        
        patterns = []
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: AIé§†å‹•ç¯„å›²ãƒãƒ©ãƒ³ã‚¹ï¼ˆãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­çµ±åˆï¼‰
        low_nums = self.predict_range_specific_ai('low', range_analysis, 2)
        mid_nums = self.predict_range_specific_ai('mid', range_analysis, 2)
        high_nums = self.predict_range_specific_ai('high', range_analysis, 2)
        
        pattern1 = low_nums + mid_nums + high_nums
        # é‡è¤‡ã‚’ç¢ºå®Ÿã«é™¤å»
        pattern1 = list(dict.fromkeys(pattern1))[:6]
        # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
        while len(pattern1) < 6:
            additional = random.randint(1, 49)
            if additional not in pattern1:
                pattern1.append(additional)
        
        confidence1 = self.calculate_ai_confidence(pattern1, ai_patterns, range_analysis, consecutive_analysis)
        
        patterns.append({
            'numbers': pattern1,
            'confidence': confidence1,
            'strategy': 'AIé§†å‹•ç¯„å›²ãƒãƒ©ãƒ³ã‚¹ï¼ˆãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­çµ±åˆï¼‰'
        })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: AIé€£ç¶šæ•°å­—å¼·åŒ–ï¼ˆãƒãƒ«ã‚³ãƒ•é€£é–çµ±åˆï¼‰
        base_nums = self.predict_range_specific_ai('low', range_analysis, 2) + \
                   self.predict_range_specific_ai('mid', range_analysis, 2) + \
                   self.predict_range_specific_ai('high', range_analysis, 2)
        consecutive_nums = self.predict_consecutive_ai(base_nums, consecutive_analysis)
        
        pattern2 = base_nums + consecutive_nums
        # é‡è¤‡ã‚’ç¢ºå®Ÿã«é™¤å»
        pattern2 = list(dict.fromkeys(pattern2))[:6]
        # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
        while len(pattern2) < 6:
            additional = random.randint(1, 49)
            if additional not in pattern2:
                pattern2.append(additional)
        
        confidence2 = self.calculate_ai_confidence(pattern2, ai_patterns, range_analysis, consecutive_analysis)
        
        patterns.append({
            'numbers': pattern2,
            'confidence': confidence2,
            'strategy': 'AIé€£ç¶šæ•°å­—å¼·åŒ–ï¼ˆãƒãƒ«ã‚³ãƒ•é€£é–çµ±åˆï¼‰'
        })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: AIçµ±è¨ˆæœ€é©åŒ–ï¼ˆæ™‚ç³»åˆ—åˆ†æçµ±åˆï¼‰
        most_frequent = ai_patterns['statistical_correlations']['most_frequent']
        least_frequent = ai_patterns['statistical_correlations']['least_frequent']
        
        # é »å‡ºæ•°å­—ã¨éé »å‡ºæ•°å­—ã‚’çµ„ã¿åˆã‚ã›
        freq_nums = [num for num, _ in most_frequent[:15]]
        rare_nums = [num for num, _ in least_frequent[:10]]
        
        # æ™‚ç³»åˆ—åˆ†æã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        time_series_weights = {}
        if 'enhanced_time_series' in ai_patterns:
            momentum_data = ai_patterns['enhanced_time_series'].get('momentum_indicators', {})
            for num in freq_nums + rare_nums:
                if num in momentum_data:
                    time_series_weights[num] = momentum_data[num]['momentum_strength']
                else:
                    time_series_weights[num] = 1.0
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠï¼ˆæ™‚ç³»åˆ—é‡ã¿ä»˜ãï¼‰
        pattern3 = []
        if time_series_weights:
            weighted_freq = [(num, time_series_weights.get(num, 1.0)) for num in freq_nums]
            weighted_rare = [(num, time_series_weights.get(num, 1.0)) for num in rare_nums]
            
            # é‡ã¿ä»˜ããƒ©ãƒ³ãƒ€ãƒ é¸æŠ
            freq_weights = [weight for _, weight in weighted_freq]
            rare_weights = [weight for _, weight in weighted_rare]
            
            if freq_weights and sum(freq_weights) > 0:
                selected_freq = random.choices(weighted_freq, weights=freq_weights, k=min(3, len(weighted_freq)))
                pattern3.extend([num for num, _ in selected_freq])
            
            if rare_weights and sum(rare_weights) > 0:
                selected_rare = random.choices(weighted_rare, weights=rare_weights, k=min(3, len(weighted_rare)))
                pattern3.extend([num for num, _ in selected_rare])
        else:
            pattern3.extend(random.sample(freq_nums, min(3, len(freq_nums))))
            pattern3.extend(random.sample(rare_nums, min(3, len(rare_nums))))
        
        # é‡è¤‡ã‚’ç¢ºå®Ÿã«é™¤å»
        pattern3 = list(dict.fromkeys(pattern3))[:6]
        # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
        while len(pattern3) < 6:
            additional = random.randint(1, 49)
            if additional not in pattern3:
                pattern3.append(additional)
        
        confidence3 = self.calculate_ai_confidence(pattern3, ai_patterns, range_analysis, consecutive_analysis)
        
        patterns.append({
            'numbers': pattern3,
            'confidence': confidence3,
            'strategy': 'AIçµ±è¨ˆæœ€é©åŒ–ï¼ˆæ™‚ç³»åˆ—åˆ†æçµ±åˆï¼‰'
        })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³4: AIå­¦ç¿’é©å¿œï¼ˆãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ä¿¡é ¼åŒºé–“çµ±åˆï¼‰
        learning_nums = []
        for success in self.learning_history['success_patterns'][-3:]:  # æœ€è¿‘3å›ã®æˆåŠŸ
            learning_nums.extend(success['numbers'])
        
        if learning_nums:
            # é‡è¤‡ã‚’é™¤å»ã—ã¦ã‹ã‚‰é¸æŠ
            unique_learning_nums = list(dict.fromkeys(learning_nums))
            pattern4 = random.sample(unique_learning_nums, min(6, len(unique_learning_nums)))
            # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
            while len(pattern4) < 6:
                additional = random.randint(1, 49)
                if additional not in pattern4:
                    pattern4.append(additional)
        else:
            # ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ä¿¡é ¼åŒºé–“ã‹ã‚‰é¸æŠ
            if 'monte_carlo_simulation' in ai_patterns:
                top_patterns = ai_patterns['monte_carlo_simulation'].get('confidence_intervals', {}).get('top_patterns', [])
                if top_patterns:
                    # æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é¸æŠ
                    best_pattern, _ = top_patterns[0]
                    pattern4 = list(best_pattern)[:6]
                    # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
                    while len(pattern4) < 6:
                        additional = random.randint(1, 49)
                        if additional not in pattern4:
                            pattern4.append(additional)
                else:
                    pattern4 = self.predict_range_specific_ai('mid', range_analysis, 3) + \
                              self.predict_range_specific_ai('low', range_analysis, 2) + \
                              self.predict_range_specific_ai('high', range_analysis, 1)
                    # é‡è¤‡ã‚’ç¢ºå®Ÿã«é™¤å»
                    pattern4 = list(dict.fromkeys(pattern4))[:6]
                    # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
                    while len(pattern4) < 6:
                        additional = random.randint(1, 49)
                        if additional not in pattern4:
                            pattern4.append(additional)
            else:
                pattern4 = self.predict_range_specific_ai('mid', range_analysis, 3) + \
                          self.predict_range_specific_ai('low', range_analysis, 2) + \
                          self.predict_range_specific_ai('high', range_analysis, 1)
                # é‡è¤‡ã‚’ç¢ºå®Ÿã«é™¤å»
                pattern4 = list(dict.fromkeys(pattern4))[:6]
                # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
                while len(pattern4) < 6:
                    additional = random.randint(1, 49)
                    if additional not in pattern4:
                        pattern4.append(additional)
        
        confidence4 = self.calculate_ai_confidence(pattern4, ai_patterns, range_analysis, consecutive_analysis)
        
        patterns.append({
            'numbers': pattern4,
            'confidence': confidence4,
            'strategy': 'AIå­¦ç¿’é©å¿œï¼ˆãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ä¿¡é ¼åŒºé–“çµ±åˆï¼‰'
        })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³5: AIæ™‚é–“çš„ã‚µã‚¤ã‚¯ãƒ«ï¼ˆãƒãƒ«ã‚³ãƒ•å®šå¸¸çŠ¶æ…‹çµ±åˆï¼‰
        temporal_nums = []
        for week_day in range(7):
            if week_day in ai_patterns['temporal_cycles']:
                temporal_nums.extend(ai_patterns['temporal_cycles'][week_day])
        
        if temporal_nums:
            # é‡è¤‡ã‚’é™¤å»ã—ã¦ã‹ã‚‰é¸æŠ
            unique_temporal_nums = list(dict.fromkeys(temporal_nums))
            pattern5 = random.sample(unique_temporal_nums, min(6, len(unique_temporal_nums)))
            # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
            while len(pattern5) < 6:
                additional = random.randint(1, 49)
                if additional not in pattern5:
                    pattern5.append(additional)
        else:
            # ãƒãƒ«ã‚³ãƒ•å®šå¸¸çŠ¶æ…‹ã‹ã‚‰é¸æŠ
            if 'markov_chain_analysis' in ai_patterns:
                steady_state = ai_patterns['markov_chain_analysis'].get('steady_state_probabilities', {})
                if steady_state:
                    # å®šå¸¸çŠ¶æ…‹ç¢ºç‡ã®é«˜ã„æ•°å­—ã‹ã‚‰é¸æŠ
                    sorted_steady = sorted(steady_state.items(), key=lambda x: x[1], reverse=True)
                    top_steady_nums = [num for num, _ in sorted_steady[:12]]
                    pattern5 = random.sample(top_steady_nums, min(6, len(top_steady_nums)))
                    # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
                    while len(pattern5) < 6:
                        additional = random.randint(1, 49)
                        if additional not in pattern5:
                            pattern5.append(additional)
                else:
                    pattern5 = self.predict_range_specific_ai('high', range_analysis, 3) + \
                              self.predict_range_specific_ai('mid', range_analysis, 2) + \
                              self.predict_range_specific_ai('low', range_analysis, 1)
                    # é‡è¤‡ã‚’ç¢ºå®Ÿã«é™¤å»
                    pattern5 = list(dict.fromkeys(pattern5))[:6]
                    # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
                    while len(pattern5) < 6:
                        additional = random.randint(1, 49)
                        if additional not in pattern5:
                            pattern5.append(additional)
            else:
                pattern5 = self.predict_range_specific_ai('high', range_analysis, 3) + \
                          self.predict_range_specific_ai('mid', range_analysis, 2) + \
                          self.predict_range_specific_ai('low', range_analysis, 1)
                # é‡è¤‡ã‚’ç¢ºå®Ÿã«é™¤å»
                pattern5 = list(dict.fromkeys(pattern5))[:6]
                # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
                while len(pattern5) < 6:
                    additional = random.randint(1, 49)
                    if additional not in pattern5:
                        pattern5.append(additional)
        
        confidence5 = self.calculate_ai_confidence(pattern5, ai_patterns, range_analysis, consecutive_analysis)
        
        patterns.append({
            'numbers': pattern5,
            'confidence': confidence5,
            'strategy': 'AIæ™‚é–“çš„ã‚µã‚¤ã‚¯ãƒ«ï¼ˆãƒãƒ«ã‚³ãƒ•å®šå¸¸çŠ¶æ…‹çµ±åˆï¼‰'
        })
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³6: AIçµ±åˆæœ€é©åŒ–ï¼ˆå…¨åˆ†ææ‰‹æ³•çµ±åˆï¼‰
        all_candidates = []
        for pattern in patterns[:5]:
            all_candidates.extend(pattern['numbers'])
        
        candidate_freq = Counter(all_candidates)
        top_candidates = [num for num, freq in candidate_freq.most_common(12)]
        
        # æ–°åˆ†ææ‰‹æ³•ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        final_weights = []
        for num in top_candidates:
            weight = candidate_freq[num]
            
            # ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ç¢ºç‡ã‚’åŠ ç®—
            if 'monte_carlo_simulation' in ai_patterns:
                monte_prob = ai_patterns['monte_carlo_simulation'].get('probability_distribution', {}).get(num, 0)
                weight += monte_prob * 1000
            
            # ãƒãƒ«ã‚³ãƒ•å®šå¸¸çŠ¶æ…‹ç¢ºç‡ã‚’åŠ ç®—
            if 'markov_chain_analysis' in ai_patterns:
                markov_prob = ai_patterns['markov_chain_analysis'].get('steady_state_probabilities', {}).get(num, 0)
                weight += markov_prob * 100
            
            # æ™‚ç³»åˆ—ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã‚’åŠ ç®—
            if 'enhanced_time_series' in ai_patterns:
                momentum_data = ai_patterns['enhanced_time_series'].get('momentum_indicators', {})
                if num in momentum_data:
                    weight += momentum_data[num]['momentum_strength'] * 10
            
            final_weights.append(weight)
        
        # é‡ã¿ä»˜ããƒ©ãƒ³ãƒ€ãƒ é¸æŠï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
        if final_weights and sum(final_weights) > 0:
            # é‡ã¿ã«åŸºã¥ã„ã¦å€™è£œã‚’é¸æŠï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
            weighted_candidates = list(zip(top_candidates, final_weights))
            weighted_candidates.sort(key=lambda x: x[1], reverse=True)
            
            # ä¸Šä½ã‹ã‚‰6å€‹é¸æŠ
            pattern6 = [num for num, _ in weighted_candidates[:6]]
        else:
            pattern6 = random.sample(top_candidates, min(6, len(top_candidates)))
        
        # 6å€‹ã«æº€ãŸãªã„å ´åˆã¯è¿½åŠ 
        while len(pattern6) < 6:
            additional = random.randint(1, 49)
            if additional not in pattern6:
                pattern6.append(additional)
        
        confidence6 = self.calculate_ai_confidence(pattern6, ai_patterns, range_analysis, consecutive_analysis)
        
        patterns.append({
            'numbers': pattern6,
            'confidence': confidence6,
            'strategy': 'AIçµ±åˆæœ€é©åŒ–ï¼ˆå…¨åˆ†ææ‰‹æ³•çµ±åˆï¼‰'
        })
        
        return patterns
    
    def predict(self, target_date):
        """Ver.5 Ultimate äºˆæ¸¬å®Ÿè¡Œï¼ˆé«˜åº¦ãªæ•°å­¦çš„åˆ†æç‰ˆï¼‰"""
        print(f"ğŸš€ ToToã€‡ãã‚“ Ver.5 Ultimate - {target_date}äºˆæ¸¬")
        print("=" * 70)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        data = self.load_data()
        if not data:
            print("âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        print(f"ğŸ¤– AIåˆ†æå®Œäº†ï¼ˆ{len(data)}å›åˆ†ï¼‰")
        print(f"ğŸ§  AIé‡ã¿: {self.ai_weights}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ
        patterns = self.generate_ultimate_patterns(data)
        
        # ãƒœãƒ¼ãƒŠã‚¹äºˆæ¸¬
        ai_patterns = self.analyze_ai_patterns(data)
        bonus_prediction = self.predict_bonus_ai(data, ai_patterns)
        
        # é«˜åº¦ãªåˆ†æçµæœã®è¡¨ç¤º
        print("ğŸ”¬ é«˜åº¦ãªæ•°å­¦çš„åˆ†æçµæœ:")
        if 'statistical_tests' in ai_patterns:
            stats = ai_patterns['statistical_tests']
            if 'chi_square_test' in stats:
                chi_sq = stats['chi_square_test']
                print(f"   ğŸ“Š ã‚«ã‚¤äºŒä¹—æ¤œå®š: Ï‡Â²={chi_sq.get('chi_square_statistic', 0):.2f}, på€¤â‰ˆ{chi_sq.get('p_value_estimate', 0):.3f}")
            
            if 'randomness_indicators' in stats:
                rand = stats['randomness_indicators']
                print(f"   ğŸ² ãƒ©ãƒ³ãƒ€ãƒ æ€§æŒ‡æ¨™: å¹³å‡é€£ç¶šæ•°={rand.get('avg_consecutive', 0):.2f}, ãƒ©ãƒ³ã®æ¤œå®šæ¯”={rand.get('runs_test', {}).get('runs_ratio', 0):.2f}")
        
        if 'theoretical_distribution' in ai_patterns:
            theo = ai_patterns['theoretical_distribution']
            if 'deviation_analysis' in theo:
                deviations = list(theo['deviation_analysis'].values())
                avg_deviation = sum(abs(d.get('deviation', 0)) for d in deviations) / len(deviations) if deviations else 0
                print(f"   ğŸ“ˆ ç†è«–å€¤ã‹ã‚‰ã®å¹³å‡åå·®: {avg_deviation:.3f}")
        
        # æ–°åˆ†ææ‰‹æ³•ã®çµæœè¡¨ç¤º
        print("ğŸš€ æ–°åˆ†ææ‰‹æ³•çµ±åˆçµæœ:")
        if 'monte_carlo_simulation' in ai_patterns:
            monte = ai_patterns['monte_carlo_simulation']
            if 'confidence_intervals' in monte and monte['confidence_intervals'].get('top_patterns'):
                top_pattern, prob = monte['confidence_intervals']['top_patterns'][0]
                print(f"   ğŸ¯ ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æœ€é©ãƒ‘ã‚¿ãƒ¼ãƒ³: {top_pattern} (ç¢ºç‡: {prob:.3f})")
        
        if 'markov_chain_analysis' in ai_patterns:
            markov = ai_patterns['markov_chain_analysis']
            if 'steady_state_probabilities' in markov:
                steady_state = markov['steady_state_probabilities']
                top_steady = sorted(steady_state.items(), key=lambda x: x[1], reverse=True)[:3]
                print(f"   ğŸ”„ ãƒãƒ«ã‚³ãƒ•å®šå¸¸çŠ¶æ…‹ä¸Šä½: {[num for num, _ in top_steady]}")
        
        if 'enhanced_time_series' in ai_patterns:
            time_series = ai_patterns['enhanced_time_series']
            if 'momentum_indicators' in time_series:
                momentum_data = time_series['momentum_indicators']
                positive_momentum = [num for num, data in momentum_data.items() if data['momentum_direction'] == 'positive']
                if positive_momentum:
                    print(f"   ğŸ“ˆ æ™‚ç³»åˆ—ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¸Šä½: {positive_momentum[:5]}")
        
        print(f"ğŸ”¢ äºˆæ¸¬ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {len(patterns)}")
        print(f"ğŸ² ãƒœãƒ¼ãƒŠã‚¹äºˆæ¸¬: {bonus_prediction}")
        print()
        
        # çµæœå‡ºåŠ›
        for i, pattern in enumerate(patterns, 1):
            numbers = pattern['numbers']
            confidence = pattern['confidence']
            strategy = pattern['strategy']
            total = sum(numbers)
            odd_count = len([n for n in numbers if n % 2 == 1])
            even_count = 6 - odd_count
            
            print(f"ã€ãƒ‘ã‚¿ãƒ¼ãƒ³{i}ã€‘ä¿¡é ¼åº¦: {confidence:.1f}% ({strategy})")
            print(f"äºˆæ¸¬æ•°å­—: {numbers}")
            print(f"åˆè¨ˆ: {total} | å¥‡æ•°/å¶æ•°: {odd_count}/{even_count}")
            print("-" * 70)
        
        print(f"ğŸ¯ Ver.5 Ultimate äºˆæ¸¬å®Œäº†ï¼")
        print("=" * 70)
        
        # çµæœä¿å­˜
        result_file = os.path.join(self.results_dir, f'result_ver5_ultimate_{target_date}.txt')
        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(f"ğŸš€ ToToã€‡ãã‚“ Ver.5 Ultimate - {target_date}äºˆæ¸¬\n")
            f.write("=" * 70 + "\n")
            f.write(f"ğŸ¤– AIåˆ†æå®Œäº†ï¼ˆ{len(data)}å›åˆ†ï¼‰\n")
            f.write(f"ğŸ§  AIé‡ã¿: {self.ai_weights}\n")
            
            # é«˜åº¦ãªåˆ†æçµæœã®ä¿å­˜
            f.write("ğŸ”¬ é«˜åº¦ãªæ•°å­¦çš„åˆ†æçµæœ:\n")
            if 'statistical_tests' in ai_patterns:
                stats = ai_patterns['statistical_tests']
                if 'chi_square_test' in stats:
                    chi_sq = stats['chi_square_test']
                    f.write(f"   ğŸ“Š ã‚«ã‚¤äºŒä¹—æ¤œå®š: Ï‡Â²={chi_sq.get('chi_square_statistic', 0):.2f}, på€¤â‰ˆ{chi_sq.get('p_value_estimate', 0):.3f}\n")
                
                if 'randomness_indicators' in stats:
                    rand = stats['randomness_indicators']
                    f.write(f"   ğŸ² ãƒ©ãƒ³ãƒ€ãƒ æ€§æŒ‡æ¨™: å¹³å‡é€£ç¶šæ•°={rand.get('avg_consecutive', 0):.2f}, ãƒ©ãƒ³ã®æ¤œå®šæ¯”={rand.get('runs_test', {}).get('runs_ratio', 0):.2f}\n")
            
            if 'theoretical_distribution' in ai_patterns:
                theo = ai_patterns['theoretical_distribution']
                if 'deviation_analysis' in theo:
                    deviations = list(theo['deviation_analysis'].values())
                    avg_deviation = sum(abs(d.get('deviation', 0)) for d in deviations) / len(deviations) if deviations else 0
                    f.write(f"   ğŸ“ˆ ç†è«–å€¤ã‹ã‚‰ã®å¹³å‡åå·®: {avg_deviation:.3f}\n")
            
            # æ–°åˆ†ææ‰‹æ³•ã®çµæœä¿å­˜
            f.write("ğŸš€ æ–°åˆ†ææ‰‹æ³•çµ±åˆçµæœ:\n")
            if 'monte_carlo_simulation' in ai_patterns:
                monte = ai_patterns['monte_carlo_simulation']
                if 'confidence_intervals' in monte and monte['confidence_intervals'].get('top_patterns'):
                    top_pattern, prob = monte['confidence_intervals']['top_patterns'][0]
                    f.write(f"   ğŸ¯ ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æœ€é©ãƒ‘ã‚¿ãƒ¼ãƒ³: {top_pattern} (ç¢ºç‡: {prob:.3f})\n")
            
            if 'markov_chain_analysis' in ai_patterns:
                markov = ai_patterns['markov_chain_analysis']
                if 'steady_state_probabilities' in markov:
                    steady_state = markov['steady_state_probabilities']
                    top_steady = sorted(steady_state.items(), key=lambda x: x[1], reverse=True)[:3]
                    f.write(f"   ğŸ”„ ãƒãƒ«ã‚³ãƒ•å®šå¸¸çŠ¶æ…‹ä¸Šä½: {[num for num, _ in top_steady]}\n")
            
            if 'enhanced_time_series' in ai_patterns:
                time_series = ai_patterns['enhanced_time_series']
                if 'momentum_indicators' in time_series:
                    momentum_data = time_series['momentum_indicators']
                    positive_momentum = [num for num, data in momentum_data.items() if data['momentum_direction'] == 'positive']
                    if positive_momentum:
                        f.write(f"   ğŸ“ˆ æ™‚ç³»åˆ—ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ä¸Šä½: {positive_momentum[:5]}\n")
            
            f.write(f"ğŸ”¢ äºˆæ¸¬ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {len(patterns)}\n")
            f.write(f"ğŸ² ãƒœãƒ¼ãƒŠã‚¹äºˆæ¸¬: {bonus_prediction}\n\n")
            
            for i, pattern in enumerate(patterns, 1):
                numbers = pattern['numbers']
                confidence = pattern['confidence']
                strategy = pattern['strategy']
                total = sum(numbers)
                odd_count = len([n for n in numbers if n % 2 == 1])
                even_count = 6 - odd_count
                
                f.write(f"ã€ãƒ‘ã‚¿ãƒ¼ãƒ³{i}ã€‘ä¿¡é ¼åº¦: {confidence:.1f}% ({strategy})\n")
                f.write(f"äºˆæ¸¬æ•°å­—: {numbers}\n")
                f.write(f"åˆè¨ˆ: {total} | å¥‡æ•°/å¶æ•°: {odd_count}/{even_count}\n")
                f.write("-" * 70 + "\n")
            
            f.write(f"ğŸ¯ Ver.5 Ultimate äºˆæ¸¬å®Œäº†ï¼\n")
            f.write("=" * 70 + "\n")

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python predictor_ver5_ultimate.py YYYY-MM-DD")
        sys.exit(1)
    
    target_date = sys.argv[1]
    predictor = TotoVer5Ultimate()
    predictor.predict(target_date) 